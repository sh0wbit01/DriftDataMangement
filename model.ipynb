{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled62.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh0wbit01/DriftDataMangement/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFUr0e7u4qpx"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import log2\n",
        "import collections\n",
        "import json\n",
        "import random\n",
        "#import mab\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyjaa4PY4b-R",
        "outputId": "98aa7c19-8e36-47af-d6f4-ef18a58839cc"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df=pd.read_csv('/content/drive/MyDrive/motor.csv')\n",
        "\n",
        "'''\n",
        "data1 = scipy.io.loadmat('/content/drive/My Drive/sea.mat')\n",
        "data = data1.get('data')\n",
        "n_feature = 3\n",
        "#pd.DataFrame(data)\n",
        "'''\n",
        "df=df.drop(df.columns[0], axis=1)\n",
        "labels=list(df.iloc[:,-1])\n",
        "labels=pd.DataFrame({'labels':labels})\n",
        "df=df.drop(df.columns[3],axis=1)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "\n",
        "#from sklearn.compose import ColumnTransformer\n",
        "'''\n",
        "onehotencoder = OneHotEncoder()\n",
        "onehotencoder.fit(labels)\n",
        "onehotlabels = onehotencoder.transform(labels).toarray()\n",
        "labels=pd.DataFrame(onehotlabels)\n",
        "labels.reset_index(drop=True,inplace=True)\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "data=pd.concat([df,labels],axis=1)\n",
        "'''\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.3, random_state=42, shuffle=True)\n",
        "\n",
        "X_train=np.asarray(X_train)\n",
        "print(X_train)\n",
        "\n",
        "y_train=np.asarray(y_train)\n",
        "print(y_train.dtype)\n",
        "X_test=np.asarray(X_test)\n",
        "y_test=np.asarray(y_test)\n",
        "print(y_test.dtype)\n",
        "\n",
        "X_train, X_test, y_train, y_test = map(torch.tensor,(X_train, X_test, y_train, y_test))\n"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[[ 0.25     1.07031 -0.28125]\n",
            " [ 0.03906  1.03906 -0.10156]\n",
            " [ 0.04688  1.       0.00781]\n",
            " ...\n",
            " [ 0.39844  1.03125 -0.1875 ]\n",
            " [-0.01562  1.11719 -0.03125]\n",
            " [ 0.16406  0.9375  -0.25781]]\n",
            "int64\n",
            "int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvPB8NtA5By0"
      },
      "source": [
        "\n",
        "class model(nn.Module):\n",
        "  def __init__(self,features,neurons,max_hidden_layers,classes):\n",
        "    super(model,self).__init__()\n",
        "\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print('using {} device...'.format(device))\n",
        "\n",
        "    self.features=features\n",
        "    self.neurons=neurons\n",
        "    self.max_hidden_layers=max_hidden_layers\n",
        "    self.classes=classes\n",
        "    \n",
        "    self.hidden_layers = []\n",
        "    self.output_layers = []\n",
        "   \n",
        "    #self.b = Parameter(torch.tensor(\n",
        "        \n",
        "        #  b), requires_grad=False).to(self.device)\n",
        "    \n",
        "    self.n = Parameter(torch.tensor(\n",
        "          0.01), requires_grad=False)\n",
        "\n",
        "\n",
        "    self.hidden_layers.append(nn.Linear(features,neurons))\n",
        "   \n",
        "    for i in range(max_hidden_layers-1):\n",
        "      self.hidden_layers.append(nn.Linear(neurons,neurons))\n",
        "\n",
        "    for i in range(max_hidden_layers):\n",
        "      self.output_layers.append(nn.Linear(neurons,classes))\n",
        "\n",
        "    \n",
        "    self.hidden_layers=nn.ModuleList(self.hidden_layers).to(device)\n",
        "    self.output_layers=nn.ModuleList(self.output_layers).to(device)\n",
        "\n",
        "\n",
        "    self.a=Parameter(torch.Tensor(self.max_hidden_layers).fill_(1/self.max_hidden_layers+1),requires_grad=False)\n",
        "    print(self.a)\n",
        "\n",
        "    '''\n",
        "    def zero_grad(self):\n",
        "      for i in range(self.max_num_hidden_layers):\n",
        "          \n",
        "        self.output_layers[i].weight.grad.data.fill_(0)\n",
        "        self.output_layers[i].bias.grad.data.fill_(0)\n",
        "        self.hidden_layers[i].weight.grad.data.fill_(0)\n",
        "        self.hidden_layers[i].bias.grad.data.fill_(0)\n",
        "        '''\n",
        "\n",
        "         \n",
        "    \n",
        " \n",
        "\n",
        "\n",
        "      \n",
        "  \n",
        "\n",
        "  def update(self,x,y):\n",
        "\n",
        "    predictions=self.forward(x)\n",
        "   # y=torch.tensor(y,dtype=torch.float64)\n",
        "#    y=torch.tensor(0.4)\n",
        "    \n",
        "\n",
        "    losses=[]\n",
        "\n",
        "    for prediction in predictions:\n",
        "      #loss=self.cross_entropy(y,prediction)\n",
        "    #  print(prediction,y)\n",
        "      criterion=nn.CrossEntropyLoss()\n",
        "      loss=criterion(prediction.unsqueeze(0),y)\n",
        "\n",
        "      losses.append(loss)\n",
        "    print(losses)\n",
        "\n",
        "\n",
        "    \n",
        "    w=[None]*len(losses)\n",
        "    b=[None]*len(losses)\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(len(losses)):\n",
        "      #print(losses[i])\n",
        "      \n",
        "      \n",
        "    #losses[i]=torch.tensor(losses[i])\n",
        "      losses[i].backward(retain_graph=True)\n",
        "\n",
        "      \n",
        "      self.output_layers[i].weight.data= -self.n * self.a[i] * self.output_layers[i].weight.grad.data\n",
        "      self.output_layers[i].bias.data= -self.n * self.a[i] * self.output_layers[i].bias.grad.data\n",
        "\n",
        "      #print(losses)\n",
        "      #print(self.output_layers[i])\n",
        "\n",
        "    \n",
        "      for j in range(i+1):\n",
        "\n",
        "        if w[j] is None:\n",
        "\n",
        "\n",
        "          w[j]=self.a[i] * self.hidden_layers[j].weight.grad.data\n",
        "          b[j]=self.a[i] * self.hidden_layers[j].weight.grad.data\n",
        "      \n",
        "        else:\n",
        "\n",
        "          w[j]+=self.a[i] * self.hidden_layers[j].weight.grad.data\n",
        "          b[j]+=self.a[i] * self.hidden_layers[j].weight.grad.data\n",
        "\n",
        "    \n",
        "    for i in range(len(losses)):\n",
        "      self.hidden_layers[i].weight.data= -self.n * w[i]\n",
        "      self.hidden_layers[i].bias.data= -self.n * b[i]\n",
        "\n",
        " #   print(self.hidden_layers)\n",
        "\n",
        "\n",
        "    self.zero_grad()\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        " \n",
        "\n",
        "  def cross_entropy(self,p, q):\n",
        "\n",
        "\t  return -sum([p[i]*log2(q[i]) for i in range(len(p))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  def forward(self,x):\n",
        "\n",
        "\n",
        "    hidden_connections = []\n",
        "    x=torch.tensor(x)\n",
        "   # print(x)\n",
        "    \n",
        "\n",
        "    \n",
        "    m=nn.Softmax(dim=0)\n",
        "\n",
        "    X=torch.sigmoid(self.hidden_layers[0](x))\n",
        "    hidden_connections.append(X)\n",
        "\n",
        "    for i in range(1, self.max_hidden_layers):\n",
        "      hidden_connections.append(torch.sigmoid(self.hidden_layers[i](hidden_connections[i-1])))\n",
        "\n",
        " \n",
        "\n",
        "   # print(hidden_connections)\n",
        "\n",
        "    output_classes=[]\n",
        "    for i in range(self.max_hidden_layers):\n",
        "    \n",
        "      output_classes.append(self.output_layers[i](hidden_connections[i]))\n",
        "\n",
        "      \n",
        "      output_classes[i]=m(output_classes[i])\n",
        "\n",
        "     # print(\"outputs{}\".format(output_classes[i]))\n",
        "\n",
        "    #print(torch.stack(output_classes))\n",
        "    \n",
        "    predictions=torch.stack(output_classes)\n",
        "    print(predictions)\n",
        "    \n",
        "  \n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "  def fit(self,x,y):\n",
        "    print(x.dtype,y.dtype)\n",
        "    self.update(x,y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "        \n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        " \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-BXNM0tdV-P",
        "outputId": "b84aaf5e-cf3a-4198-ed7a-5d6b5e7c01a7"
      },
      "source": [
        "\n",
        "\n",
        "model=model(3,10,5,4)\n",
        "model.double()\n",
        "#model.forward(X_train[0])\n",
        "model.fit(X_train[0],y_train[0])"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cpu device...\n",
            "Parameter containing:\n",
            "tensor([1.2000, 1.2000, 1.2000, 1.2000, 1.2000])\n",
            "torch.float64 torch.int64\n",
            "tensor([[0.1700, 0.1749, 0.3612, 0.2940],\n",
            "        [0.1531, 0.2340, 0.4070, 0.2058],\n",
            "        [0.2482, 0.1530, 0.2757, 0.3231],\n",
            "        [0.3610, 0.2463, 0.1725, 0.2202],\n",
            "        [0.1855, 0.2954, 0.3605, 0.1586]], dtype=torch.float64,\n",
            "       grad_fn=<StackBackward>)\n",
            "[tensor(1.3456, dtype=torch.float64, grad_fn=<NllLossBackward>), tensor(1.4351, dtype=torch.float64, grad_fn=<NllLossBackward>), tensor(1.3151, dtype=torch.float64, grad_fn=<NllLossBackward>), tensor(1.4185, dtype=torch.float64, grad_fn=<NllLossBackward>), tensor(1.4811, dtype=torch.float64, grad_fn=<NllLossBackward>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:147: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuB1budI4ckU",
        "outputId": "3a7cae3f-25f8-4054-bf18-bf1b68d71d7a"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor(0.0100, dtype=torch.float64), Parameter containing:\n",
              " tensor([1.2000, 1.2000, 1.2000, 1.2000, 1.2000], dtype=torch.float64), Parameter containing:\n",
              " tensor([[-2.3722e-04, -1.0156e-03,  2.6688e-04],\n",
              "         [ 5.7058e-05,  2.4428e-04, -6.4191e-05],\n",
              "         [ 3.3249e-05,  1.4235e-04, -3.7405e-05],\n",
              "         [-9.3203e-05, -3.9902e-04,  1.0485e-04],\n",
              "         [-2.3245e-05, -9.9516e-05,  2.6150e-05],\n",
              "         [ 8.5412e-05,  3.6567e-04, -9.6088e-05],\n",
              "         [ 3.8927e-04,  1.6666e-03, -4.3793e-04],\n",
              "         [ 1.9559e-04,  8.3735e-04, -2.2003e-04],\n",
              "         [-7.8648e-05, -3.3671e-04,  8.8479e-05],\n",
              "         [ 1.8835e-05,  8.0636e-05, -2.1189e-05]], dtype=torch.float64,\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[-2.3722e-04, -1.0156e-03,  2.6688e-04],\n",
              "         [ 5.7058e-05,  2.4428e-04, -6.4191e-05],\n",
              "         [ 3.3249e-05,  1.4235e-04, -3.7405e-05],\n",
              "         [-9.3203e-05, -3.9902e-04,  1.0485e-04],\n",
              "         [-2.3245e-05, -9.9516e-05,  2.6150e-05],\n",
              "         [ 8.5412e-05,  3.6567e-04, -9.6088e-05],\n",
              "         [ 3.8927e-04,  1.6666e-03, -4.3793e-04],\n",
              "         [ 1.9559e-04,  8.3735e-04, -2.2003e-04],\n",
              "         [-7.8648e-05, -3.3671e-04,  8.8479e-05],\n",
              "         [ 1.8835e-05,  8.0636e-05, -2.1189e-05]], dtype=torch.float64,\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[ 2.3618e-05,  1.5170e-05,  2.5163e-05,  1.8988e-05,  2.3975e-05,\n",
              "           1.2802e-05,  2.2072e-05,  2.9635e-05,  2.4406e-05,  2.8360e-05],\n",
              "         [-2.1936e-04, -1.4090e-04, -2.3371e-04, -1.7636e-04, -2.2268e-04,\n",
              "          -1.1890e-04, -2.0501e-04, -2.7525e-04, -2.2668e-04, -2.6340e-04],\n",
              "         [-9.7945e-05, -6.2913e-05, -1.0436e-04, -7.8746e-05, -9.9429e-05,\n",
              "          -5.3090e-05, -9.1537e-05, -1.2290e-04, -1.0122e-04, -1.1761e-04],\n",
              "         [ 3.0402e-04,  1.9528e-04,  3.2392e-04,  2.4442e-04,  3.0862e-04,\n",
              "           1.6479e-04,  2.8413e-04,  3.8148e-04,  3.1417e-04,  3.6507e-04],\n",
              "         [ 5.4269e-05,  3.4858e-05,  5.7821e-05,  4.3631e-05,  5.5091e-05,\n",
              "           2.9416e-05,  5.0718e-05,  6.8095e-05,  5.6081e-05,  6.5166e-05],\n",
              "         [-1.6950e-04, -1.0888e-04, -1.8060e-04, -1.3628e-04, -1.7207e-04,\n",
              "          -9.1878e-05, -1.5841e-04, -2.1269e-04, -1.7516e-04, -2.0354e-04],\n",
              "         [-3.6508e-04, -2.3450e-04, -3.8897e-04, -2.9352e-04, -3.7061e-04,\n",
              "          -1.9789e-04, -3.4119e-04, -4.5810e-04, -3.7727e-04, -4.3839e-04],\n",
              "         [-1.5687e-04, -1.0076e-04, -1.6713e-04, -1.2612e-04, -1.5924e-04,\n",
              "          -8.5027e-05, -1.4660e-04, -1.9683e-04, -1.6210e-04, -1.8836e-04],\n",
              "         [ 4.6105e-05,  2.9614e-05,  4.9122e-05,  3.7067e-05,  4.6803e-05,\n",
              "           2.4990e-05,  4.3088e-05,  5.7851e-05,  4.7644e-05,  5.5362e-05],\n",
              "         [-2.5667e-04, -1.6487e-04, -2.7347e-04, -2.0636e-04, -2.6056e-04,\n",
              "          -1.3912e-04, -2.3988e-04, -3.2207e-04, -2.6524e-04, -3.0821e-04]],\n",
              "        dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([[ 2.3618e-05,  1.5170e-05,  2.5163e-05,  1.8988e-05,  2.3975e-05,\n",
              "           1.2802e-05,  2.2072e-05,  2.9635e-05,  2.4406e-05,  2.8360e-05],\n",
              "         [-2.1936e-04, -1.4090e-04, -2.3371e-04, -1.7636e-04, -2.2268e-04,\n",
              "          -1.1890e-04, -2.0501e-04, -2.7525e-04, -2.2668e-04, -2.6340e-04],\n",
              "         [-9.7945e-05, -6.2913e-05, -1.0436e-04, -7.8746e-05, -9.9429e-05,\n",
              "          -5.3090e-05, -9.1537e-05, -1.2290e-04, -1.0122e-04, -1.1761e-04],\n",
              "         [ 3.0402e-04,  1.9528e-04,  3.2392e-04,  2.4442e-04,  3.0862e-04,\n",
              "           1.6479e-04,  2.8413e-04,  3.8148e-04,  3.1417e-04,  3.6507e-04],\n",
              "         [ 5.4269e-05,  3.4858e-05,  5.7821e-05,  4.3631e-05,  5.5091e-05,\n",
              "           2.9416e-05,  5.0718e-05,  6.8095e-05,  5.6081e-05,  6.5166e-05],\n",
              "         [-1.6950e-04, -1.0888e-04, -1.8060e-04, -1.3628e-04, -1.7207e-04,\n",
              "          -9.1878e-05, -1.5841e-04, -2.1269e-04, -1.7516e-04, -2.0354e-04],\n",
              "         [-3.6508e-04, -2.3450e-04, -3.8897e-04, -2.9352e-04, -3.7061e-04,\n",
              "          -1.9789e-04, -3.4119e-04, -4.5810e-04, -3.7727e-04, -4.3839e-04],\n",
              "         [-1.5687e-04, -1.0076e-04, -1.6713e-04, -1.2612e-04, -1.5924e-04,\n",
              "          -8.5027e-05, -1.4660e-04, -1.9683e-04, -1.6210e-04, -1.8836e-04],\n",
              "         [ 4.6105e-05,  2.9614e-05,  4.9122e-05,  3.7067e-05,  4.6803e-05,\n",
              "           2.4990e-05,  4.3088e-05,  5.7851e-05,  4.7644e-05,  5.5362e-05],\n",
              "         [-2.5667e-04, -1.6487e-04, -2.7347e-04, -2.0636e-04, -2.6056e-04,\n",
              "          -1.3912e-04, -2.3988e-04, -3.2207e-04, -2.6524e-04, -3.0821e-04]],\n",
              "        dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([[-0.0003, -0.0002, -0.0003, -0.0002, -0.0003, -0.0002, -0.0003, -0.0002,\n",
              "          -0.0002, -0.0004],\n",
              "         [ 0.0003,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0003,  0.0002,\n",
              "           0.0002,  0.0003],\n",
              "         [ 0.0003,  0.0002,  0.0003,  0.0002,  0.0003,  0.0002,  0.0003,  0.0002,\n",
              "           0.0002,  0.0003],\n",
              "         [-0.0004, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0004, -0.0003,\n",
              "          -0.0003, -0.0004],\n",
              "         [ 0.0004,  0.0003,  0.0003,  0.0003,  0.0003,  0.0003,  0.0004,  0.0003,\n",
              "           0.0003,  0.0004],\n",
              "         [ 0.0005,  0.0003,  0.0004,  0.0003,  0.0004,  0.0004,  0.0005,  0.0004,\n",
              "           0.0004,  0.0005],\n",
              "         [ 0.0003,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0003,  0.0002,\n",
              "           0.0002,  0.0003],\n",
              "         [ 0.0002,  0.0001,  0.0002,  0.0001,  0.0002,  0.0001,  0.0002,  0.0001,\n",
              "           0.0001,  0.0002],\n",
              "         [-0.0002, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0002, -0.0001,\n",
              "          -0.0001, -0.0002],\n",
              "         [ 0.0004,  0.0003,  0.0003,  0.0003,  0.0003,  0.0003,  0.0004,  0.0003,\n",
              "           0.0003,  0.0004]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([[-0.0003, -0.0002, -0.0003, -0.0002, -0.0003, -0.0002, -0.0003, -0.0002,\n",
              "          -0.0002, -0.0004],\n",
              "         [ 0.0003,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0003,  0.0002,\n",
              "           0.0002,  0.0003],\n",
              "         [ 0.0003,  0.0002,  0.0003,  0.0002,  0.0003,  0.0002,  0.0003,  0.0002,\n",
              "           0.0002,  0.0003],\n",
              "         [-0.0004, -0.0003, -0.0003, -0.0003, -0.0003, -0.0003, -0.0004, -0.0003,\n",
              "          -0.0003, -0.0004],\n",
              "         [ 0.0004,  0.0003,  0.0003,  0.0003,  0.0003,  0.0003,  0.0004,  0.0003,\n",
              "           0.0003,  0.0004],\n",
              "         [ 0.0005,  0.0003,  0.0004,  0.0003,  0.0004,  0.0004,  0.0005,  0.0004,\n",
              "           0.0004,  0.0005],\n",
              "         [ 0.0003,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,  0.0003,  0.0002,\n",
              "           0.0002,  0.0003],\n",
              "         [ 0.0002,  0.0001,  0.0002,  0.0001,  0.0002,  0.0001,  0.0002,  0.0001,\n",
              "           0.0001,  0.0002],\n",
              "         [-0.0002, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -0.0002, -0.0001,\n",
              "          -0.0001, -0.0002],\n",
              "         [ 0.0004,  0.0003,  0.0003,  0.0003,  0.0003,  0.0003,  0.0004,  0.0003,\n",
              "           0.0003,  0.0004]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([[-4.4604e-05, -4.3304e-05, -4.5102e-05, -4.6455e-05, -3.4976e-05,\n",
              "          -4.5518e-05, -4.3816e-05, -5.1291e-05, -6.8196e-05, -6.2607e-05],\n",
              "         [ 1.2071e-04,  1.1720e-04,  1.2206e-04,  1.2573e-04,  9.4659e-05,\n",
              "           1.2319e-04,  1.1858e-04,  1.3881e-04,  1.8457e-04,  1.6944e-04],\n",
              "         [ 1.0250e-04,  9.9509e-05,  1.0364e-04,  1.0675e-04,  8.0372e-05,\n",
              "           1.0460e-04,  1.0068e-04,  1.1786e-04,  1.5671e-04,  1.4386e-04],\n",
              "         [-5.7379e-05, -5.5707e-05, -5.8019e-05, -5.9761e-05, -4.4994e-05,\n",
              "          -5.8555e-05, -5.6365e-05, -6.5981e-05, -8.7728e-05, -8.0538e-05],\n",
              "         [-6.1249e-05, -5.9464e-05, -6.1933e-05, -6.3792e-05, -4.8029e-05,\n",
              "          -6.2505e-05, -6.0167e-05, -7.0431e-05, -9.3646e-05, -8.5970e-05],\n",
              "         [ 7.0544e-05,  6.8488e-05,  7.1332e-05,  7.3473e-05,  5.5317e-05,\n",
              "           7.1990e-05,  6.9297e-05,  8.1120e-05,  1.0786e-04,  9.9017e-05],\n",
              "         [ 1.1727e-04,  1.1385e-04,  1.1858e-04,  1.2214e-04,  9.1959e-05,\n",
              "           1.1968e-04,  1.1520e-04,  1.3485e-04,  1.7930e-04,  1.6460e-04],\n",
              "         [-1.2205e-04, -1.1849e-04, -1.2341e-04, -1.2712e-04, -9.5705e-05,\n",
              "          -1.2455e-04, -1.1989e-04, -1.4035e-04, -1.8661e-04, -1.7131e-04],\n",
              "         [-1.1652e-04, -1.1313e-04, -1.1782e-04, -1.2136e-04, -9.1371e-05,\n",
              "          -1.1891e-04, -1.1446e-04, -1.3399e-04, -1.7816e-04, -1.6355e-04],\n",
              "         [-2.1082e-04, -2.0468e-04, -2.1318e-04, -2.1957e-04, -1.6532e-04,\n",
              "          -2.1514e-04, -2.0710e-04, -2.4243e-04, -3.2233e-04, -2.9591e-04]],\n",
              "        dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([[-4.4604e-05, -4.3304e-05, -4.5102e-05, -4.6455e-05, -3.4976e-05,\n",
              "          -4.5518e-05, -4.3816e-05, -5.1291e-05, -6.8196e-05, -6.2607e-05],\n",
              "         [ 1.2071e-04,  1.1720e-04,  1.2206e-04,  1.2573e-04,  9.4659e-05,\n",
              "           1.2319e-04,  1.1858e-04,  1.3881e-04,  1.8457e-04,  1.6944e-04],\n",
              "         [ 1.0250e-04,  9.9509e-05,  1.0364e-04,  1.0675e-04,  8.0372e-05,\n",
              "           1.0460e-04,  1.0068e-04,  1.1786e-04,  1.5671e-04,  1.4386e-04],\n",
              "         [-5.7379e-05, -5.5707e-05, -5.8019e-05, -5.9761e-05, -4.4994e-05,\n",
              "          -5.8555e-05, -5.6365e-05, -6.5981e-05, -8.7728e-05, -8.0538e-05],\n",
              "         [-6.1249e-05, -5.9464e-05, -6.1933e-05, -6.3792e-05, -4.8029e-05,\n",
              "          -6.2505e-05, -6.0167e-05, -7.0431e-05, -9.3646e-05, -8.5970e-05],\n",
              "         [ 7.0544e-05,  6.8488e-05,  7.1332e-05,  7.3473e-05,  5.5317e-05,\n",
              "           7.1990e-05,  6.9297e-05,  8.1120e-05,  1.0786e-04,  9.9017e-05],\n",
              "         [ 1.1727e-04,  1.1385e-04,  1.1858e-04,  1.2214e-04,  9.1959e-05,\n",
              "           1.1968e-04,  1.1520e-04,  1.3485e-04,  1.7930e-04,  1.6460e-04],\n",
              "         [-1.2205e-04, -1.1849e-04, -1.2341e-04, -1.2712e-04, -9.5705e-05,\n",
              "          -1.2455e-04, -1.1989e-04, -1.4035e-04, -1.8661e-04, -1.7131e-04],\n",
              "         [-1.1652e-04, -1.1313e-04, -1.1782e-04, -1.2136e-04, -9.1371e-05,\n",
              "          -1.1891e-04, -1.1446e-04, -1.3399e-04, -1.7816e-04, -1.6355e-04],\n",
              "         [-2.1082e-04, -2.0468e-04, -2.1318e-04, -2.1957e-04, -1.6532e-04,\n",
              "          -2.1514e-04, -2.0710e-04, -2.4243e-04, -3.2233e-04, -2.9591e-04]],\n",
              "        dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([[ 4.5446e-05,  5.5362e-05,  4.6070e-05,  4.4845e-05,  3.7807e-05,\n",
              "           3.5897e-05,  2.7321e-05,  3.3388e-05,  4.0395e-05,  4.7691e-05],\n",
              "         [-6.0884e-05, -7.4170e-05, -6.1720e-05, -6.0079e-05, -5.0651e-05,\n",
              "          -4.8092e-05, -3.6603e-05, -4.4730e-05, -5.4117e-05, -6.3892e-05],\n",
              "         [-2.6528e-05, -3.2317e-05, -2.6893e-05, -2.6178e-05, -2.2070e-05,\n",
              "          -2.0954e-05, -1.5948e-05, -1.9490e-05, -2.3580e-05, -2.7839e-05],\n",
              "         [-6.8886e-05, -8.3917e-05, -6.9832e-05, -6.7975e-05, -5.7308e-05,\n",
              "          -5.4412e-05, -4.1413e-05, -5.0609e-05, -6.1229e-05, -7.2289e-05],\n",
              "         [-5.8329e-05, -7.1056e-05, -5.9130e-05, -5.7557e-05, -4.8525e-05,\n",
              "          -4.6073e-05, -3.5066e-05, -4.2853e-05, -5.1846e-05, -6.1210e-05],\n",
              "         [ 6.3141e-05,  7.6918e-05,  6.4008e-05,  6.2306e-05,  5.2528e-05,\n",
              "           4.9874e-05,  3.7959e-05,  4.6388e-05,  5.6123e-05,  6.6260e-05],\n",
              "         [-3.2794e-05, -3.9949e-05, -3.3244e-05, -3.2360e-05, -2.7282e-05,\n",
              "          -2.5903e-05, -1.9715e-05, -2.4093e-05, -2.9149e-05, -3.4414e-05],\n",
              "         [ 1.8764e-06,  2.2859e-06,  1.9022e-06,  1.8516e-06,  1.5611e-06,\n",
              "           1.4822e-06,  1.1281e-06,  1.3786e-06,  1.6679e-06,  1.9691e-06],\n",
              "         [-1.0816e-04, -1.3176e-04, -1.0965e-04, -1.0673e-04, -8.9982e-05,\n",
              "          -8.5435e-05, -6.5025e-05, -7.9464e-05, -9.6140e-05, -1.1350e-04],\n",
              "         [ 1.1675e-05,  1.4223e-05,  1.1835e-05,  1.1521e-05,  9.7127e-06,\n",
              "           9.2219e-06,  7.0188e-06,  8.5774e-06,  1.0377e-05,  1.2252e-05]],\n",
              "        dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([[ 4.5446e-05,  5.5362e-05,  4.6070e-05,  4.4845e-05,  3.7807e-05,\n",
              "           3.5897e-05,  2.7321e-05,  3.3388e-05,  4.0395e-05,  4.7691e-05],\n",
              "         [-6.0884e-05, -7.4170e-05, -6.1720e-05, -6.0079e-05, -5.0651e-05,\n",
              "          -4.8092e-05, -3.6603e-05, -4.4730e-05, -5.4117e-05, -6.3892e-05],\n",
              "         [-2.6528e-05, -3.2317e-05, -2.6893e-05, -2.6178e-05, -2.2070e-05,\n",
              "          -2.0954e-05, -1.5948e-05, -1.9490e-05, -2.3580e-05, -2.7839e-05],\n",
              "         [-6.8886e-05, -8.3917e-05, -6.9832e-05, -6.7975e-05, -5.7308e-05,\n",
              "          -5.4412e-05, -4.1413e-05, -5.0609e-05, -6.1229e-05, -7.2289e-05],\n",
              "         [-5.8329e-05, -7.1056e-05, -5.9130e-05, -5.7557e-05, -4.8525e-05,\n",
              "          -4.6073e-05, -3.5066e-05, -4.2853e-05, -5.1846e-05, -6.1210e-05],\n",
              "         [ 6.3141e-05,  7.6918e-05,  6.4008e-05,  6.2306e-05,  5.2528e-05,\n",
              "           4.9874e-05,  3.7959e-05,  4.6388e-05,  5.6123e-05,  6.6260e-05],\n",
              "         [-3.2794e-05, -3.9949e-05, -3.3244e-05, -3.2360e-05, -2.7282e-05,\n",
              "          -2.5903e-05, -1.9715e-05, -2.4093e-05, -2.9149e-05, -3.4414e-05],\n",
              "         [ 1.8764e-06,  2.2859e-06,  1.9022e-06,  1.8516e-06,  1.5611e-06,\n",
              "           1.4822e-06,  1.1281e-06,  1.3786e-06,  1.6679e-06,  1.9691e-06],\n",
              "         [-1.0816e-04, -1.3176e-04, -1.0965e-04, -1.0673e-04, -8.9982e-05,\n",
              "          -8.5435e-05, -6.5025e-05, -7.9464e-05, -9.6140e-05, -1.1350e-04],\n",
              "         [ 1.1675e-05,  1.4223e-05,  1.1835e-05,  1.1521e-05,  9.7127e-06,\n",
              "           9.2219e-06,  7.0188e-06,  8.5774e-06,  1.0377e-05,  1.2252e-05]],\n",
              "        dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([[-0.0003, -0.0002, -0.0003, -0.0002, -0.0003, -0.0001, -0.0003, -0.0003,\n",
              "          -0.0003, -0.0003],\n",
              "         [-0.0003, -0.0002, -0.0003, -0.0002, -0.0003, -0.0002, -0.0003, -0.0004,\n",
              "          -0.0003, -0.0003],\n",
              "         [-0.0007, -0.0004, -0.0007, -0.0005, -0.0007, -0.0004, -0.0006, -0.0009,\n",
              "          -0.0007, -0.0008],\n",
              "         [ 0.0012,  0.0008,  0.0013,  0.0010,  0.0012,  0.0007,  0.0011,  0.0015,\n",
              "           0.0013,  0.0015]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([-0.0005, -0.0006, -0.0014,  0.0025], dtype=torch.float64,\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[-0.0002, -0.0001, -0.0002, -0.0001, -0.0002, -0.0001, -0.0002, -0.0001,\n",
              "          -0.0001, -0.0002],\n",
              "         [-0.0003, -0.0002, -0.0003, -0.0002, -0.0003, -0.0002, -0.0003, -0.0002,\n",
              "          -0.0002, -0.0003],\n",
              "         [-0.0007, -0.0005, -0.0006, -0.0005, -0.0006, -0.0005, -0.0007, -0.0005,\n",
              "          -0.0005, -0.0008],\n",
              "         [ 0.0012,  0.0008,  0.0010,  0.0008,  0.0011,  0.0009,  0.0012,  0.0009,\n",
              "           0.0009,  0.0013]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([-0.0003, -0.0005, -0.0012,  0.0020], dtype=torch.float64,\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[-0.0004, -0.0004, -0.0004, -0.0005, -0.0003, -0.0004, -0.0004, -0.0005,\n",
              "          -0.0007, -0.0006],\n",
              "         [-0.0003, -0.0002, -0.0003, -0.0003, -0.0002, -0.0003, -0.0002, -0.0003,\n",
              "          -0.0004, -0.0004],\n",
              "         [-0.0005, -0.0005, -0.0005, -0.0005, -0.0004, -0.0005, -0.0005, -0.0006,\n",
              "          -0.0008, -0.0007],\n",
              "         [ 0.0012,  0.0012,  0.0012,  0.0012,  0.0009,  0.0012,  0.0012,  0.0014,\n",
              "           0.0018,  0.0017]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([-0.0009, -0.0005, -0.0011,  0.0026], dtype=torch.float64,\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[-0.0006, -0.0007, -0.0006, -0.0005, -0.0005, -0.0004, -0.0003, -0.0004,\n",
              "          -0.0005, -0.0006],\n",
              "         [-0.0003, -0.0004, -0.0003, -0.0003, -0.0003, -0.0003, -0.0002, -0.0002,\n",
              "          -0.0003, -0.0003],\n",
              "         [-0.0002, -0.0003, -0.0002, -0.0002, -0.0002, -0.0002, -0.0001, -0.0002,\n",
              "          -0.0002, -0.0002],\n",
              "         [ 0.0011,  0.0013,  0.0011,  0.0011,  0.0009,  0.0009,  0.0007,  0.0008,\n",
              "           0.0010,  0.0012]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([-0.0011, -0.0006, -0.0004,  0.0021], dtype=torch.float64,\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[-0.0001, -0.0001, -0.0002, -0.0002, -0.0001, -0.0001, -0.0001, -0.0002,\n",
              "          -0.0001, -0.0001],\n",
              "         [-0.0002, -0.0002, -0.0004, -0.0003, -0.0003, -0.0002, -0.0003, -0.0003,\n",
              "          -0.0002, -0.0003],\n",
              "         [-0.0003, -0.0003, -0.0005, -0.0004, -0.0004, -0.0003, -0.0004, -0.0004,\n",
              "          -0.0003, -0.0004],\n",
              "         [ 0.0007,  0.0007,  0.0010,  0.0010,  0.0008,  0.0006,  0.0008,  0.0009,\n",
              "           0.0007,  0.0007]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
              " tensor([-0.0003, -0.0006, -0.0008,  0.0017], dtype=torch.float64,\n",
              "        requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWfdlMDcnznm"
      },
      "source": [
        "\n",
        "\n",
        "#model.state_dict\n",
        "#model.named_modules\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yom6ZBzP6nAb"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#list(model.parameters())\n"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpRQYZaB6TFi"
      },
      "source": [
        "\n"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNFrcKB7KvhW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTw-0HouOq6y"
      },
      "source": [
        ""
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZWJg9fVSTM-"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XRXgyo-l7q8"
      },
      "source": [
        "\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YcDft3Ryors"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}